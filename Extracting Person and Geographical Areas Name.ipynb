{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment (Part B).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1pohr_Ae10tdRj72kK405iiW2gKD_P1Sz",
      "authorship_tag": "ABX9TyP1/3Lf8V4SaA7ljZWxsUI5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yQAZEbFRgAR",
        "colab_type": "text"
      },
      "source": [
        "### ***3. Using NLTK Find the user names,City mentioned in the top 5000 records and store in list and add another column to list called Entity like if name is name of person then new column should contain \"Person\" if name is name of City then new column should be \"City\"***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e51747hW0XQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5a61260a-18b6-493c-a62d-8139053cdbfd"
      },
      "source": [
        "#Now performing same operation via NLTK\n",
        "import nltk\n",
        "#For Tokenization\n",
        "nltk.download('punkt')\n",
        "#Used for Tagging \n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "#Dowloading maxent \n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYPR6uut3Pe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagger = nltk.PerceptronTagger()\n",
        "chunker = nltk.data.load(nltk.chunk._MULTICLASS_NE_CHUNKER)\n",
        "\n",
        "# Function to find Person tags from Text\n",
        "def Extract_ner_Person(text):\n",
        "  chunk = chunker.parse(tagger.tag(nltk.word_tokenize(text,preserve_line=True)))\n",
        "  ne = set()\n",
        "  for tree in chunk.subtrees(filter=lambda t: t.label() == 'PERSON'):\n",
        "    ne.add(' '.join([child[0] for child in tree.leaves()]))\n",
        "    return ne\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9pMxTBs5gsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to find GPE tags from Text\n",
        "def Extract_ner_GPE(text):\n",
        "  chunk = chunker.parse(tagger.tag(nltk.word_tokenize(text,preserve_line=True)))\n",
        "  ne = set()\n",
        "  for tree in chunk.subtrees(filter=lambda t: t.label() == 'GPE'):\n",
        "    ne.add(' '.join([child[0] for child in tree.leaves()]))\n",
        "    return ne"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsGo3SL84czc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df14e08a-b5e2-4430-9609-af7726a0e5ce"
      },
      "source": [
        "#Testing Extract_ner_Person function\n",
        "text1  = 'Neha Delhi One of the other reviewers has mentioned that after watching just 1 Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence which set in right from the word GO Trust me this is not a show for the faint hearted or timid This show pulls no punches with regards to drugs sex or violence Its is hardcore in the classic use of the word It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary It focuses mainly on Emerald City an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda Em City is home to many Aryans Muslims gangstas Latinos Christians Italians Irish and more so scuffles death stares dodgy dealings and shady agreements are never far away I would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare Forget pretty pictures painted for mainstream audiences forget charm forget romance OZ doesn t mess around The first episode I ever saw struck me as so nasty it was surreal I couldn t say I was ready for it but as I watched more I developed a taste for Oz and got accustomed to the high levels of graphic violence Not just violence but injustice crooked guards who ll be sold out for a nickel inmates who ll kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience Watching Oz you may become comfortable with what is uncomfortable viewing thats if you can get in touch with your darker side '\n",
        "print(Extract_ner_Person(text1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Neha'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii4gTXcv4KJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a41521f-f094-4b1d-f466-c6bce623db56"
      },
      "source": [
        "#Testing Extract_ner_GPE function\n",
        "text2 = 'Angela Sandra Bullock is a computer expert but being shy and somewhat of a recluse she does all of her work from the confines of her condo Just as she is about to take a vacation in Mexico a co worker sends her a computer disc with disturbing information on it Angela agrees to meet with her fellow employee but he mysteriously dies in a plane crash Angela heads to Mexico but takes the disc with her While she is sunning on the beach a terrific looking gentleman named Jack Jeremy Northam makes overtures to her She falls for them and the two end up on a boat to Cozumel However Jack works for the folks who generated the secret information on the disc and he is out to get it Even after Angela escapes from his clutches and lands back in the USA Jack makes things difficult He changes Angela s identity on every computer across the nation making her lose her condo her bank account everything Can Angela a computer whiz beat Jack at his own game This very exciting movie has many assets First Bullock and Northam are two very beautiful interesting actors and their presence adds immediate captivation The script is very clever and sure in its knowledge of the capabilities of computers and their relevance in today s world The costumes sets production and direction of the movie are also quite wonderful And despite how it sounds there is a great deal of exciting action as Angela goes on the run to defeat her enemy If you love thrillers without unnecessary bloodshed or violence this is a great choice It delivers twists and turns with great frequency making it possible for the viewer to net a very good evening of entertainment '\n",
        "print(Extract_ner_GPE(text2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Mexico'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgvhz6bATc2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing pandas to load our saved dataset\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pSd5ku95MEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining final DataFrame on which we are going to perform further operations.\n",
        "DT_Final= pd.read_csv('/content/drive/My Drive/Colab Notebooks/DataSet/IMDB.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZyTVeNfKrwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As our Dataset is very heavy and it is utilizing whole RAM so let's split our dataset in 2 parts (2500 each set)\n",
        "#This will take less time as well as it will not consume our whole RAM\n",
        "DT_Final_1 = pd.DataFrame()\n",
        "DT_Final_2 = pd.DataFrame()\n",
        "DT_Final_1 = DT_Final.loc[:2499,:]\n",
        "DT_Final_2 = DT_Final.loc[2500:4999,:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA_BGlDxLWS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3299f1bd-324e-4a8f-d76f-11d6ec747178"
      },
      "source": [
        "#Checking shape of both sliced Datasets\n",
        "print(DT_Final_1.shape)\n",
        "print(DT_Final_2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 3)\n",
            "(2500, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yW4tXJf5OQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c60242cb-745a-47c2-a1f6-1c2fae4b3de7"
      },
      "source": [
        "#This will add a column in DT_Final_1 dataset which contains Person Name Only\n",
        "DT_Final_1['Person']= DT_Final_1.apply(lambda row: Extract_ner_Person(row['review']), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tknWhO6wS1Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4834ba77-2b3b-462c-89e8-35adac88e6e6"
      },
      "source": [
        "print(DT_Final_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Unnamed: 0  ...           Person\n",
            "0              0  ...             {Oz}\n",
            "1              1  ...  {Michael Sheen}\n",
            "2              2  ...    {Match Point}\n",
            "3              3  ...           {Jake}\n",
            "4              4  ...         {Petter}\n",
            "...          ...  ...              ...\n",
            "2495        2495  ...   {Costa Gavras}\n",
            "2496        2496  ...      {Tim Krabb}\n",
            "2497        2497  ...  {George Taylor}\n",
            "2498        2498  ...     {Paul Lukas}\n",
            "2499        2499  ...          {Mardi}\n",
            "\n",
            "[2500 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD9b2ar4URJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d229c760-b385-4e4f-bb1c-db03f7377189"
      },
      "source": [
        "#This will add a column in DT_Final_2 dataset which contains contains Person Name Only\n",
        "DT_Final_2['Person']= DT_Final_2.apply(lambda row: Extract_ner_Person(row['review']), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et4Hd2dgUZam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c9640dd8-15c2-4b5c-eebd-afc5afa22c9d"
      },
      "source": [
        "print(DT_Final_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Unnamed: 0  ...             Person\n",
            "2500        2500  ...               None\n",
            "2501        2501  ...    {Samuel Fuller}\n",
            "2502        2502  ...             {Lexi}\n",
            "2503        2503  ...              {H O}\n",
            "2504        2504  ...     {Robert Fryer}\n",
            "...          ...  ...                ...\n",
            "4995        4995  ...  {Denise Cheshire}\n",
            "4996        4996  ...       {Stalingrad}\n",
            "4997        4997  ...           {Jet Li}\n",
            "4998        4998  ...       {Chris Gore}\n",
            "4999        4999  ...               None\n",
            "\n",
            "[2500 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60aui77D922X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1e67da12-6b56-4e90-fc2f-a8319723be76"
      },
      "source": [
        "#This will add a column in DT_Final_1 dataset which contains GPE(Countries,Cties,States) Names Only\n",
        "DT_Final_1['GPE']= DT_Final_1.apply(lambda row: Extract_ner_GPE(row['review']), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbpsmkvEVivg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "892ac8b9-13bd-4f09-e619-55733daa9594"
      },
      "source": [
        "DT_Final_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Person</th>\n",
              "      <th>GPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Oz}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A wonderful little production The filming tech...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Michael Sheen}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Match Point}</td>\n",
              "      <td>{Woody}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Basically there s a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{Jake}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Petter Mattei s Love in the Time of Money is a...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Petter}</td>\n",
              "      <td>{Money}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>2495</td>\n",
              "      <td>Another great movie by Costa Gavras It s a gre...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{Costa Gavras}</td>\n",
              "      <td>{Latin}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>2496</td>\n",
              "      <td>Though structured totally different from the b...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Tim Krabb}</td>\n",
              "      <td>{American}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>2497</td>\n",
              "      <td>Handsome and dashing British airline pilot Geo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{George Taylor}</td>\n",
              "      <td>{Handsome}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>2498</td>\n",
              "      <td>This film breeches the fine line between satir...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{Paul Lukas}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>2499</td>\n",
              "      <td>Mardi Gras Made in China provides a wonderful ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Mardi}</td>\n",
              "      <td>{China}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2500 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...         GPE\n",
              "0              0  ...        None\n",
              "1              1  ...        None\n",
              "2              2  ...     {Woody}\n",
              "3              3  ...        None\n",
              "4              4  ...     {Money}\n",
              "...          ...  ...         ...\n",
              "2495        2495  ...     {Latin}\n",
              "2496        2496  ...  {American}\n",
              "2497        2497  ...  {Handsome}\n",
              "2498        2498  ...        None\n",
              "2499        2499  ...     {China}\n",
              "\n",
              "[2500 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pa0m24q5T-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "cc06a4f8-4105-4604-d36d-43987f38e45e"
      },
      "source": [
        "#This will add a column in DT_Final_1 dataset which contains GPE(Countries,Cties,States) Names Only\n",
        "DT_Final_2['GPE']= DT_Final_2.apply(lambda row: Extract_ner_GPE(row['review']), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fUNP-KSVmjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "297c3745-5834-4233-f796-4063d8fcdf85"
      },
      "source": [
        "DT_Final_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Person</th>\n",
              "      <th>GPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>2500</td>\n",
              "      <td>But I can t say how I really feel about this p...</td>\n",
              "      <td>negative</td>\n",
              "      <td>None</td>\n",
              "      <td>{America}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2501</th>\n",
              "      <td>2501</td>\n",
              "      <td>From the opening scene aboard a crowded train ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Samuel Fuller}</td>\n",
              "      <td>{Huston}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2502</th>\n",
              "      <td>2502</td>\n",
              "      <td>I have seen a couple movies on eating disorder...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Lexi}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2503</th>\n",
              "      <td>2503</td>\n",
              "      <td>H O T S is not for those that want hardcore po...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{H O}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2504</th>\n",
              "      <td>2504</td>\n",
              "      <td>THAT S certainly a strange way to promote a fi...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{Robert Fryer}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>4995</td>\n",
              "      <td>An interesting slasher film with multiple susp...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{Denise Cheshire}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>4996</td>\n",
              "      <td>i watched this series when it first came out i...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Stalingrad}</td>\n",
              "      <td>{Russian}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>4997</td>\n",
              "      <td>Once again Jet Li brings his charismatic prese...</td>\n",
              "      <td>positive</td>\n",
              "      <td>{Jet Li}</td>\n",
              "      <td>{American}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>4998</td>\n",
              "      <td>I rented this movie after hearing Chris Gore s...</td>\n",
              "      <td>negative</td>\n",
              "      <td>{Chris Gore}</td>\n",
              "      <td>{Japanese}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>4999</td>\n",
              "      <td>This was a big disappointment for me I think t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>None</td>\n",
              "      <td>{Mastroianni}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2500 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...            GPE\n",
              "2500        2500  ...      {America}\n",
              "2501        2501  ...       {Huston}\n",
              "2502        2502  ...           None\n",
              "2503        2503  ...           None\n",
              "2504        2504  ...           None\n",
              "...          ...  ...            ...\n",
              "4995        4995  ...           None\n",
              "4996        4996  ...      {Russian}\n",
              "4997        4997  ...     {American}\n",
              "4998        4998  ...     {Japanese}\n",
              "4999        4999  ...  {Mastroianni}\n",
              "\n",
              "[2500 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPkw2VAwXNxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now Let's concatenate both Dataframes\n",
        "Frames = [DT_Final_1 , DT_Final_2]\n",
        "DT_Final = pd.concat(Frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPgDytqFX0wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing an Unnamed Index Row\n",
        "IMDB_Entities = pd.DataFrame()\n",
        "IMDB_Entities['PERSON'] = DT_Final['Person']\n",
        "IMDB_Entities['CITY'] = DT_Final['GPE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1jbDC_Q5Xb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "0ed2eab2-5476-4990-d115-a072c8880a85"
      },
      "source": [
        "#Let's check the final Dataframe we got after all this operation\n",
        "IMDB_Entities.shape\n",
        "IMDB_Entities.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PERSON</th>\n",
              "      <th>CITY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{Oz}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{Michael Sheen}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{Match Point}</td>\n",
              "      <td>{Woody}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{Jake}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{Petter}</td>\n",
              "      <td>{Money}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{Paul Lukas}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{Seahunt}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{How}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{Bad}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{Great Camp}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            PERSON     CITY\n",
              "0             {Oz}     None\n",
              "1  {Michael Sheen}     None\n",
              "2    {Match Point}  {Woody}\n",
              "3           {Jake}     None\n",
              "4         {Petter}  {Money}\n",
              "5     {Paul Lukas}     None\n",
              "6        {Seahunt}     None\n",
              "7            {How}     None\n",
              "8            {Bad}     None\n",
              "9     {Great Camp}     None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EizCBAyrFFAZ",
        "colab_type": "text"
      },
      "source": [
        "## ***4. Store above data in DataFrame and convert  it to JSON and  return that JSON from function.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYGUwoiVFJE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As our data is already in Dataframe so coversion is not required \n",
        "#Writing a function to convert our Dataframe to JSON file and save it.\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6oH0MNQFlzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to convert Dataframe to JSON\n",
        "def Dataframe_to_JSON(DF_Set):\n",
        "  d = DF_Set.to_json(orient='records')\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/DataSet/IMDB_Entities.json', 'w') as f:\n",
        "    f.write(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQeEJ7T0F_gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving our Data by using Function created just above\n",
        "Dataframe_to_JSON(IMDB_Entities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfnEdv7uE-rK",
        "colab_type": "text"
      },
      "source": [
        "Now, I have completed my Fourth Task successfully. Now i will move to my next and Final task of API creation. I will perform that task on other Notebook with my saved JSON data (API Creation).\n",
        "\n",
        "(NOTE : I can continue with this Notebook as well but as i am completing this task with some intervals whenever i am opening this notebook i need to re-run all codes to make things continue and it is taking lot of Time so i am choosing to work on separate notebook with saved data.)\n",
        "\n",
        "Thanks,\n",
        "\n",
        "Neha Kumari.\n",
        "\n",
        "\n"
      ]
    }
  ]
}
